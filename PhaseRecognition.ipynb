{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"xAmKr9LiQopa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699514046914,"user_tz":-330,"elapsed":32597,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}},"outputId":"0245667e-6654-4380-bf2b-d40595ebcbe1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting albumentations==0.4.6\n","  Downloading albumentations-0.4.6.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==0.4.6) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from albumentations==0.4.6) (1.11.3)\n","Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==0.4.6) (0.4.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==0.4.6) (6.0.1)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==0.4.6) (4.8.0.76)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.16.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (9.4.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.7.1)\n","Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.19.3)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.31.6)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.0.2)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (3.2.1)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2023.9.26)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.4.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (23.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (4.44.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n","Building wheels for collected packages: albumentations\n","  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65152 sha256=05a2b3465a6119d5d06261f3953e17a717019ddeaa6b54530311f5651e97f2ee\n","  Stored in directory: /root/.cache/pip/wheels/f9/d7/0c/6ed42fd872f7d1af78b25045f8b16be330f2c70ae72c83e37d\n","Successfully built albumentations\n","Installing collected packages: albumentations\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 1.3.1\n","    Uninstalling albumentations-1.3.1:\n","      Successfully uninstalled albumentations-1.3.1\n","Successfully installed albumentations-0.4.6\n","Collecting segmentation_models_pytorch\n","  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (0.16.0+cu118)\n","Collecting pretrainedmodels==0.7.4 (from segmentation_models_pytorch)\n","  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting efficientnet-pytorch==0.7.1 (from segmentation_models_pytorch)\n","  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting timm==0.9.2 (from segmentation_models_pytorch)\n","  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (4.66.1)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from segmentation_models_pytorch) (9.4.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.0+cu118)\n","Collecting munch (from pretrainedmodels==0.7.4->segmentation_models_pytorch)\n","  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.2->segmentation_models_pytorch) (6.0.1)\n","Collecting huggingface-hub (from timm==0.9.2->segmentation_models_pytorch)\n","  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors (from timm==0.9.2->segmentation_models_pytorch)\n","  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (2.31.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.2->segmentation_models_pytorch) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision>=0.5.0->segmentation_models_pytorch) (2023.7.22)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation_models_pytorch) (1.3.0)\n","Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=5a54a25b3fd0fcde4478724f694b2b0adb95f96d906e52d9000893e3d3f58e0e\n","  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n","  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60944 sha256=3d8e7b88ab9053bbbd67a5f108dce7d3b622098c796c3c2f9b662101a18ce97a\n","  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\n","Successfully built efficientnet-pytorch pretrainedmodels\n","Installing collected packages: safetensors, munch, huggingface-hub, efficientnet-pytorch, timm, pretrainedmodels, segmentation_models_pytorch\n","Successfully installed efficientnet-pytorch-0.7.1 huggingface-hub-0.19.0 munch-4.0.0 pretrainedmodels-0.7.4 safetensors-0.4.0 segmentation_models_pytorch-0.3.3 timm-0.9.2\n","Collecting torchmetrics\n","  Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n","Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n","  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n","Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n","Installing collected packages: lightning-utilities, torchmetrics\n","Successfully installed lightning-utilities-0.9.0 torchmetrics-1.2.0\n","Collecting monai\n","  Downloading monai-1.3.0-202310121228-py3-none-any.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from monai) (1.23.5)\n","Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.1.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->monai) (1.3.0)\n","Installing collected packages: monai\n","Successfully installed monai-1.3.0\n"]}],"source":["!pip install albumentations==0.4.6\n","!pip install segmentation_models_pytorch\n","!pip install torchmetrics\n","!pip install monai"]},{"cell_type":"markdown","metadata":{"id":"zPbsP3wNU-bJ"},"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-W5_HoMJQnjM","executionInfo":{"status":"ok","timestamp":1699514062052,"user_tz":-330,"elapsed":15147,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["#utils\n","import torch\n","import os\n","import random\n","import numpy as np\n","from pathlib import Path\n","from typing import List\n","from sklearn.model_selection import train_test_split\n","import collections\n","from collections import defaultdict\n","from functools import reduce\n","\n","#viz\n","import matplotlib.pyplot as plt\n","\n","#images\n","from skimage.io import imread\n","import albumentations as albu\n","from albumentations.pytorch import ToTensor\n","from albumentations.augmentations.transforms import MotionBlur\n","\n","#torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import torch.nn as nn\n","import torchvision.models\n","import segmentation_models_pytorch as smp\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","from torchsummary import summary\n","import ssl\n","from tqdm import tqdm\n","from PIL import Image\n","ssl._create_default_https_context = ssl._create_unverified_context\n","\n","from torchmetrics.functional import dice\n","import monai.metrics\n","from natsort import natsorted"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"C0enzfacOU0k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699514108176,"user_tz":-330,"elapsed":46133,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}},"outputId":"3adf294d-9a20-4ca7-a8f8-5d3383efc864"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"1sjsek-wx2t0","executionInfo":{"status":"ok","timestamp":1699514108176,"user_tz":-330,"elapsed":24,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["root = Path(\"/content/drive/MyDrive/ETVProject/ETV_Project/dataset_v2_fom_cp_cropped/\")\n","test_chiari_images = Path(\"/content/drive/MyDrive/ETVProject/ETV_Project/chiari_etv_2fps/images\")\n","test_chiari_masks = Path(\"/content/drive/MyDrive/ETVProject/ETV_Project/chiari_etv_2fps/masks\")\n","#test_chiari_masks = None"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Yf0E62DHx-7p","executionInfo":{"status":"ok","timestamp":1699514119246,"user_tz":-330,"elapsed":11094,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["test_images_chiari = sorted(test_chiari_images.glob(\"*.png\"))\n","test_images_chiari = natsorted(test_images_chiari)\n","test_masks_chiari = None\n","#test_images_chiari"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"z7Iy08Z7yg66","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699514119247,"user_tz":-330,"elapsed":49,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}},"outputId":"e318fed0-bb41-4226-f61a-70c3647bfc46"},"outputs":[{"output_type":"stream","name":"stdout","text":["device cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('device', device)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"KKijLIf-7Kfb","executionInfo":{"status":"ok","timestamp":1699514119247,"user_tz":-330,"elapsed":45,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["color_dict = {'background': [  0,   0,   0],\n","          'lpca':[  0,   0, 128], # BLUE 163 occurances\n","          'rmb':[  0, 128,   0],  # GREEN 182 occurances\n","          'cp':[  0, 128, 128],   # CYAN 38 occurances\n","          'fom':[128,   0,   0],  # RED 46 occurances\n","          'rpca':[128,   0, 128], # PURPLE 229 occurances\n","          'lmb':[128, 128,   0],  # YELLOW 173 occurances\n","          'ca':[128, 128, 128]}   # GRAY 87 occurances\n","colors = list(color_dict.values())"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"F8LPXPIW5pd_","executionInfo":{"status":"ok","timestamp":1699514119247,"user_tz":-330,"elapsed":44,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["def encode_mask(mask, colors = colors):\n","  semantic_map = []\n","  for color in colors:\n","    equality = np.equal(mask, color)\n","    class_map = np.all(equality, axis = -1)\n","    semantic_map.append(class_map)\n","\n","  semantic_map = np.stack(semantic_map, axis = -1)\n","\n","  return semantic_map.astype('uint8')"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"uFBJIJGj5vmM","executionInfo":{"status":"ok","timestamp":1699514119247,"user_tz":-330,"elapsed":43,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["def reverse_transform(inp):\n","  inp = inp.cpu().numpy().transpose((1, 2, 0))\n","  inp = np.clip(inp, 0, 1)\n","  inp = (inp * 255).astype(np.uint8)\n","\n","  return inp"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"OsVtp5Q45pnd","executionInfo":{"status":"ok","timestamp":1699514119248,"user_tz":-330,"elapsed":43,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["def reverse_one_hot(image):\n","    \"\"\"\n","    Transform a 2D array in one-hot format (depth is num_classes),\n","    to a 2D array with only 1 channel, where each pixel value is\n","    the classified class key.\n","    # Arguments\n","        image: The one-hot format image\n","\n","    # Returns\n","        A 2D array with the same width and hieght as the input, but\n","        with a depth size of 1, where each pixel value is the classified\n","        class key.\n","    \"\"\"\n","    x = np.argmax(reverse_transform(image), axis = -1)\n","    return x"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"eR2xba-L5r7A","executionInfo":{"status":"ok","timestamp":1699514119248,"user_tz":-330,"elapsed":43,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["def colour_code_segmentation(image):\n","    \"\"\"\n","    Given a 1-channel array of class keys, colour code the segmentation results.\n","    # Arguments\n","        image: single channel array where each value represents the class key.\n","        label_values\n","\n","    # Returns\n","        Colour coded image for segmentation visualization\n","    \"\"\"\n","    colour_codes = np.array(colors)\n","    # print(colour_codes)\n","    # print(image.astype(int))\n","    # print(np.unique(image.astype(int)))\n","    x = colour_codes[image.astype(int)]\n","\n","    return x"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"xlUcN6tC6HZC","executionInfo":{"status":"ok","timestamp":1699514119248,"user_tz":-330,"elapsed":42,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":12,"metadata":{"id":"djyr-4xU0m8O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699514133313,"user_tz":-330,"elapsed":14107,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}},"outputId":"e96c6b16-319c-4f04-f061-5c43a62c658f"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-b121ed2d.pth\n","100%|██████████| 230M/230M [00:01<00:00, 237MB/s]\n"]}],"source":["\n","netClass = smp.Unet\n","modelDict = {\n","    \"encoder_name\": \"resnet152\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n","    \"encoder_weights\": \"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n","    \"in_channels\": 3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n","    \"classes\": 8,                      # model output channels (number of classes in your dataset)\n","    \"activation\":'softmax2d',# TO DO activation function softmax2d\n","    # \"decoder_attention_type\":\"scse\"\n","}\n","\n","net = netClass(**modelDict)\n","model = netClass(**modelDict)\n","model2 = model.to(device)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"_t1qIb8fqYpo","executionInfo":{"status":"ok","timestamp":1699514133314,"user_tz":-330,"elapsed":51,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["def dice_loss(pred, target, smooth = 1.):\n","    pred = pred.contiguous()\n","    target = target.contiguous()\n","    # print(pred)\n","    intersection = (pred * target).sum(dim=2).sum(dim=2)\n","\n","    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n","\n","    return loss.mean()\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"Pg3wcB5f83hl","executionInfo":{"status":"ok","timestamp":1699514133314,"user_tz":-330,"elapsed":49,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["def calc_loss(loss_fn, pred, target, metrics, bce_weight=0.5):\n","    bce = F.cross_entropy(pred, target)\n","\n","    # pred = torch.sigmoid(pred)\n","    dice = dice_loss(pred, target)\n","    # print(type(pred[0]), type(target[0]))\n","    # print(pred.dtype, target.long())\n","    # print(pred.size(), target.size())\n","    # dice = loss_fn(pred, target)\n","\n","    loss = bce * bce_weight + dice * (1 - bce_weight)\n","    # loss = dice * (1 - bce_weight)\n","\n","    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n","    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n","    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n","    return loss"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"sHC9CADJ7JSS","executionInfo":{"status":"ok","timestamp":1699514133314,"user_tz":-330,"elapsed":48,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["def plot_side_by_side(img_arrays, count, batch_size, save_location):\n","    flatten_list = reduce(lambda x,y: x+y, zip(*img_arrays))\n","\n","    plot_img_array(np.array(flatten_list),count, batch_size,save_location, ncol=len(img_arrays))\n","\n","def plot_img_array(img_array, count, batch_size, save_location, ncol=3 ):\n","    nrow = len(img_array) // ncol\n","    f, plots = plt.subplots(nrow, ncol, sharex='all', sharey='all', figsize=(ncol * 4, nrow * 4), squeeze = False)\n","    for i in range(len(img_array)):\n","        plots[i // ncol, i % ncol]\n","        plots[i // ncol, i % ncol].imshow(img_array[i])\n","    plt.savefig(save_location +str(count)  + '.jpg')"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"LlALIeMj6CW3","executionInfo":{"status":"ok","timestamp":1699514133314,"user_tz":-330,"elapsed":48,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["def predict_images_test(loader, batch_size, model, save_location):\n","    i = 1\n","    epoch_samples = 0\n","    dice = 0\n","    metrics = defaultdict(float)\n","    count = 1\n","    saver = 1\n","    phase1_idx = phase2_idx = phase3_idx = 0\n","    flag1 = flag2 = flag3 = False\n","    fps = 2\n","    limit = fps * 2\n","\n","    phase1_count = phase2_count = 0\n","    with torch.no_grad():\n","        for data_dict in tqdm(loader):\n","            inputs = data_dict[\"image\"].to(device)\n","            predicted = model(inputs)\n","\n","            for i in range(len(predicted)):\n","              predicted_image = Image.fromarray(colour_code_segmentation(reverse_one_hot(predicted[i])).astype('uint8'), 'RGB')\n","\n","              colors = predicted_image.getcolors()\n","              converted_colors = []\n","              for color in colors:\n","                if(color[1] != (0, 0, 0)):\n","                  converted_colors.append(color[1])\n","              pixdata = predicted_image.load()\n","              for y in range(predicted_image.size[1]):\n","                  for x in range(predicted_image.size[0]):\n","                      if (0, 0, 128) in converted_colors:\n","                        if pixdata[x,y] != (0, 0, 128) and pixdata[x, y] != (0, 128, 0) and pixdata[x, y] != (128, 128, 0) and pixdata[x, y] != (128, 0, 128):\n","                          pixdata[x, y] = (0, 0, 0)\n","                      else:\n","                        if pixdata[x,y] != (128, 0, 0) and pixdata[x, y] != (0, 128, 128):\n","                          pixdata[x, y] = (0, 0, 0)\n","                      if (0, 128, 128) not in converted_colors:\n","                        if pixdata[x, y]==(128, 0, 0):\n","                          pixdata[x, y] = (0, 0, 0)\n","\n","              if (128, 0, 0) in converted_colors and (0, 128, 128) in converted_colors and flag1 == False:\n","                flag1 = True\n","                phase1_idx = count\n","\n","              if (flag1 == True and flag2 == False):\n","                if (128, 0, 0) not in converted_colors and (0, 128, 128) not in converted_colors:\n","                  phase1_count+=1\n","                  if phase1_count>=limit:\n","                    flag2 = True\n","                    phase2_idx = count\n","                else:\n","                  phase1_count = 0\n","\n","              if flag1==True and flag2==True and flag3 == False:\n","                if (128, 128, 0) in converted_colors and (0, 128, 0) in converted_colors:\n","                  phase2_count+=1\n","                  if phase2_count>=limit:\n","                    flag3 = True\n","                    phase3_idx = count\n","                else:\n","                  phase2_count = 0\n","\n","\n","              encoded_mask = encode_mask(predicted_image)\n","              encoded_mask = encoded_mask.transpose(2, 0, 1)\n","              predicted[i] = torch.Tensor(encoded_mask)\n","\n","            count+=1\n","\n","            #print(\"Image number\", count)\n","            #image.show()\n","\n","            #print(predicted)\n","            #print(type(predicted))\n","\n","            input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n","            predicted_rgb = [colour_code_segmentation(reverse_one_hot(predicted_mask)) for predicted_mask in predicted.cpu()]\n","\n","            for rgbImage, inputImage in zip(predicted, input_images_rgb):\n","\n","                rgbImagePIL = Image.fromarray(colour_code_segmentation(reverse_one_hot(rgbImage)).astype('uint8'), 'RGB')\n","                inputImagePIL = Image.fromarray(inputImage)\n","\n","                #rgbImagePIL.save(\"/content/drive/MyDrive/ETVProject/ETV_Project/predictions/\" + str(saver) + \"_predicted_mask.png\")\n","                #inputImagePIL.save(\"/content/drive/MyDrive/ETVProject/ETV_Project/predictions/\" + str(saver) + \"_input.png\")\n","\n","                overlay_img = Image.blend(inputImagePIL, rgbImagePIL, 0.5)\n","\n","                overlay_img.save(\"/content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/\" + str(saver) + \"_masked_frame.png\")\n","\n","                saver += 1\n","\n","\n","            #print(predicted_rgb)\n","            #print(type(predicted_rgb))\n","            #print(\"Length \", predicted.shape)\n","            #for image in predicted_rgb:\n","              #plt.savefig(save_location + '/image'+str(i)  + '.jpg')\n","              #i += 1\n","            #plot_side_by_side([predicted_rgb], count, batch_size, save_location)\n","\n","\n","    return (phase1_idx, phase2_idx, phase3_idx)"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"PQSX3LWdkZh-","executionInfo":{"status":"ok","timestamp":1699514133314,"user_tz":-330,"elapsed":47,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["class SegmentationDataset(Dataset):\n","  def __init__(self, images:List[Path], masks:List[Path] = None, transform = None) -> None:\n","    self.images = images\n","    self.masks = masks\n","    self.transform = transform\n","\n","  def __len__(self) -> int:\n","    return len(self.images)\n","\n","  def __getitem__(self, idx:int) -> dict:\n","    image_path = self.images[idx]\n","    image = imread(self.images[idx])\n","    result = {\"image\":image}\n","    if self.masks is not None:\n","      mask = imread(self.masks[idx])\n","      mask = mask[:,:,0:3]\n","      result[\"mask\"] = encode_mask(mask)\n","    if self.transform is not None:\n","      result = self.transform(**result)\n","        #** is used for variable number of args\n","    if self.masks is not None:\n","      result['mask'] = torch.ceil(result['mask'][0])\n","      result['mask'] = torch.swapaxes(torch.swapaxes(result['mask'], 0, 2), 1, 2)\n","      result[\"mask_no_color\"] = reverse_one_hot(result[\"mask\"])\n","\n","    result[\"filename\"] = image_path.name\n","    return result\n","# train_dataset = SegmentationDataset(all_images, all_masks, train_transforms)\n","# train_dataset[0]"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"KgmSstKqQVqk","executionInfo":{"status":"ok","timestamp":1699514133316,"user_tz":-330,"elapsed":47,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["BORDER_CONSTANT = 0\n","def pre_transforms(crop_size=500, image_size=300):\n","    # return []\n","    # return [albu.CenterCrop(480, 640, p=1), albu.Resize(300, 300, p=1)]\n","    return [albu.Resize(224, 224, p=1)]\n","\n","# Probability = 0.5\n","def augmentation_transforms():\n","    return [\n","            albu.VerticalFlip(p=0.5),\n","            albu.RandomRotate90(p=0.5),\n","            albu.Blur(10, p = 0.2),\n","            albu.CLAHE(p=0.8),\n","            albu.RandomBrightness(limit = 0.3,p = 0.5),\n","            albu.RandomContrast(limit = 0.2, p = 0.7),\n","            albu.RandomGamma(p=0.8),\n","    ]\n","\n","def post_transforms():\n","    # we use ImageNet image normalization\n","    # and convert it to torch.Tensor\n","    # return [albu.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), ToTensor()] # TO DO use image net normalize [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n","    return [ToTensor()] # This also divides image & mask by 255 # TO DO use image net normalize [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n","\n","def compose(transforms_to_compose):\n","    # combine all augmentations into single pipeline\n","    result = albu.Compose([\n","      item for sublist in transforms_to_compose for item in sublist\n","    ])\n","    return result\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"dMuN1iwV4RYU","executionInfo":{"status":"ok","timestamp":1699514133317,"user_tz":-330,"elapsed":47,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["aug = augmentation_transforms()\n","\n","# image_transforms = compose([\n","#     pre_transforms(),\n","#     aug['imageOnly'],\n","# ])\n","# both_transforms = compose([\n","#     pre_transforms(),\n","#     aug['both'],\n","#     post_transforms(),\n","# ])\n","train_transforms = compose([\n","    pre_transforms(),\n","    augmentation_transforms(),\n","    post_transforms(),\n","\n","])\n","train_transforms2 = compose([\n","    pre_transforms(),\n","    post_transforms(),\n","\n","])\n","valid_transforms = test_transforms = compose([pre_transforms(),  post_transforms()])\n","# valid_transforms = test_transforms = compose([post_transforms()])\n","\n","\n","# show_transforms = compose([pre_transforms(), augmentation_transforms(), post_transforms()])\n","# show_transforms = compose([post_transforms()])"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"ne0NOM287kBc","executionInfo":{"status":"ok","timestamp":1699514133317,"user_tz":-330,"elapsed":47,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":20,"metadata":{"id":"nYohPIkA6U-P","executionInfo":{"status":"ok","timestamp":1699514133317,"user_tz":-330,"elapsed":46,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["test_dataset_chiari = SegmentationDataset(test_images_chiari, test_masks_chiari, test_transforms)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"tSWxKDOkyhzF","executionInfo":{"status":"ok","timestamp":1699514133317,"user_tz":-330,"elapsed":46,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["\n","\n","loader_test_video_chiari = DataLoader(\n","    test_dataset_chiari,\n","    batch_size=1,\n","    shuffle = False,\n","    num_workers=2,\n","    drop_last=True\n",")"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"wb2venmcyCvX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699514334849,"user_tz":-330,"elapsed":201577,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}},"outputId":"f857ac0f-09a5-4800-cdf9-5c8954f3bca5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Testing for Batch size 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 319/319 [03:13<00:00,  1.65it/s]\n"]}],"source":["print(\"Testing for Batch size 2\")\n","model2_loaded = netClass(**modelDict)\n","model2_loaded = model2_loaded.to(device)\n","model2_loaded.load_state_dict(torch.load('/content/drive/MyDrive/ETVProject/ETV_Project/dataset_v2_fom_cp_cropped/model_bs2_random_try.pt', map_location=device))\n","model2_loaded.eval()\n","idxs = predict_images_test(loader_test_video_chiari, 1, model2_loaded, '/content/drive/MyDrive/ETVProject/ETV_Project/Testvideo1_predictions3')\n","phase1_idx, phase2_idx, phase3_idx = idxs"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"4_ZdG3WXG5iq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699514342890,"user_tz":-330,"elapsed":8054,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}},"outputId":"cb40016d-cf4f-4216-f6ab-b3be2e719bab"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics==8.0.20\n","  Downloading ultralytics-8.0.20-py3-none-any.whl (261 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/261.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m194.6/261.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.2/261.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (4.8.0.76)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (9.4.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (1.11.3)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (2.1.0+cu118)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (0.16.0+cu118)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (4.66.1)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (2.14.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (0.12.2)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (7.34.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics==8.0.20) (5.9.5)\n","Collecting thop>=0.1.1 (from ultralytics==8.0.20)\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Collecting sentry-sdk (from ultralytics==8.0.20)\n","  Downloading sentry_sdk-1.34.0-py2.py3-none-any.whl (243 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.9/243.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (4.44.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->ultralytics==8.0.20) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics==8.0.20) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.20) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.20) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.20) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics==8.0.20) (2023.7.22)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (1.59.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (3.5.1)\n","Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->ultralytics==8.0.20) (3.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->ultralytics==8.0.20) (2.1.0)\n","Collecting jedi>=0.16 (from ipython->ultralytics==8.0.20)\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (3.0.39)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ultralytics==8.0.20) (4.8.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics==8.0.20) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics==8.0.20) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics==8.0.20) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->ultralytics==8.0.20) (1.3.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ultralytics==8.0.20) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ultralytics==8.0.20) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ultralytics==8.0.20) (0.2.9)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->ultralytics==8.0.20) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->ultralytics==8.0.20) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->ultralytics==8.0.20) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->ultralytics==8.0.20) (3.2.2)\n","Installing collected packages: sentry-sdk, jedi, thop, ultralytics\n","Successfully installed jedi-0.19.1 sentry-sdk-1.34.0 thop-0.1.1.post2209072238 ultralytics-8.0.20\n"]}],"source":["!pip install ultralytics==8.0.20\n","import ultralytics"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"I_Av7Uq2HK6x","executionInfo":{"status":"ok","timestamp":1699514342891,"user_tz":-330,"elapsed":27,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["from ultralytics import YOLO\n","from tqdm import tqdm\n","from PIL import Image"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"MTBELZQSv3wP","executionInfo":{"status":"ok","timestamp":1699514342891,"user_tz":-330,"elapsed":26,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["import os.path\n","from natsort import natsorted\n","imlist = natsorted(os.listdir(\"/content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3\"))\n"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"pfVrgwIkuMKY","executionInfo":{"status":"ok","timestamp":1699514347292,"user_tz":-330,"elapsed":4426,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["model = YOLO('/content/drive/MyDrive/ETVProject/ETV_Project/detect/train/weights/best.pt')"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"VADygyNauoYR","executionInfo":{"status":"ok","timestamp":1699514347293,"user_tz":-330,"elapsed":18,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["from pathlib import Path"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"I6sBm7bOfRa1","executionInfo":{"status":"ok","timestamp":1699514347293,"user_tz":-330,"elapsed":15,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["source = '/content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3'"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"qzjPwQysuyBx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699514354117,"user_tz":-330,"elapsed":6839,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}},"outputId":"7215846f-60bf-43e2-e7af-a701478ab7d3"},"outputs":[{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/319 [00:00<?, ?it/s]Ultralytics YOLOv8.0.20 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","Model summary (fused): 168 layers, 11126358 parameters, 0 gradients, 28.4 GFLOPs\n","100%|██████████| 319/319 [00:06<00:00, 46.09it/s]\n"]}],"source":["results=[]\n","for im in tqdm(imlist):\n","  if '.png' in im:\n","    #print(source+'/'+im)\n","    results.append(model(source+'/'+im))"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"jXtBEyo3PZBP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699514354117,"user_tz":-330,"elapsed":85,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}},"outputId":"d9a33852-6e0a-4b8f-8265-254729b3f027"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 64.00000,  33.00000,  99.00000, 215.00000,   0.30889,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  23.00000, 154.00000,  93.00000,   0.67890,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  24.00000, 155.00000,  93.00000,   0.45304,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  24.00000, 154.00000,  93.00000,   0.77734,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  24.00000, 154.00000,  94.00000,   0.71176,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  24.00000, 153.00000,  93.00000,   0.52418,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  24.00000, 153.00000,  95.00000,   0.66869,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  24.00000, 153.00000,  95.00000,   0.40881,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  29.00000, 153.00000,  98.00000,   0.77340,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 91.00000,  29.00000, 152.00000, 102.00000,   0.79696,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 91.00000,  30.00000, 152.00000, 104.00000,   0.84468,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 91.00000,  31.00000, 153.00000, 105.00000,   0.80266,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 91.00000,  30.00000, 154.00000, 103.00000,   0.77517,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 91.00000,  30.00000, 154.00000, 103.00000,   0.80249,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 89.00000,  32.00000, 154.00000, 106.00000,   0.82335,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 90.00000,  30.00000, 155.00000, 104.00000,   0.81745,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  29.00000, 156.00000, 102.00000,   0.80047,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  29.00000, 155.00000, 102.00000,   0.80984,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  29.00000, 155.00000, 101.00000,   0.81116,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  27.00000, 154.00000, 100.00000,   0.75186,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  28.00000, 155.00000, 101.00000,   0.83816,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  28.00000, 155.00000, 101.00000,   0.81264,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 91.00000,  28.00000, 155.00000, 102.00000,   0.82973,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  28.00000, 154.00000, 111.00000,   0.88200,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  29.00000, 154.00000, 124.00000,   0.88322,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  29.00000, 153.00000, 124.00000,   0.87872,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  29.00000, 153.00000, 125.00000,   0.87896,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  29.00000, 154.00000, 127.00000,   0.88138,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  29.00000, 154.00000, 129.00000,   0.87620,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  29.00000, 153.00000, 130.00000,   0.87654,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  29.00000, 153.00000, 132.00000,   0.87898,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 95.00000,  29.00000, 153.00000, 130.00000,   0.88049,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  29.00000, 153.00000, 132.00000,   0.88370,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  29.00000, 153.00000, 131.00000,   0.87366,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  31.00000, 154.00000, 134.00000,   0.87979,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  34.00000, 154.00000, 136.00000,   0.88248,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 95.00000,  35.00000, 154.00000, 134.00000,   0.87768,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  33.00000, 154.00000, 135.00000,   0.88490,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  29.00000, 153.00000, 128.00000,   0.88086,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  29.00000, 153.00000, 128.00000,   0.88167,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  30.00000, 153.00000, 128.00000,   0.88114,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  29.00000, 153.00000, 128.00000,   0.87652,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  29.00000, 153.00000, 130.00000,   0.88025,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 95.00000,  28.00000, 153.00000, 136.00000,   0.88522,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  28.00000, 153.00000, 137.00000,   0.88983,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  28.00000, 154.00000, 136.00000,   0.88181,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  28.00000, 153.00000, 138.00000,   0.88929,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  29.00000, 154.00000, 139.00000,   0.88515,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  29.00000, 154.00000, 140.00000,   0.88539,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  28.00000, 153.00000, 138.00000,   0.89036,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  28.00000, 153.00000, 140.00000,   0.88324,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  28.00000, 153.00000, 140.00000,   0.89562,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  28.00000, 153.00000, 140.00000,   0.89750,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  28.00000, 153.00000, 140.00000,   0.89145,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  27.00000, 153.00000, 140.00000,   0.89200,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  28.00000, 152.00000, 140.00000,   0.89452,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  28.00000, 153.00000, 140.00000,   0.89027,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  27.00000, 153.00000, 140.00000,   0.88915,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 91.00000,  28.00000, 152.00000, 140.00000,   0.89471,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 91.00000,  29.00000, 153.00000, 141.00000,   0.88990,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 90.00000,  28.00000, 152.00000, 142.00000,   0.88200,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 91.00000,  28.00000, 152.00000, 142.00000,   0.87393,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  26.00000, 152.00000, 141.00000,   0.88591,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 89.00000,  27.00000, 152.00000, 141.00000,   0.87961,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 90.00000,  27.00000, 153.00000, 142.00000,   0.87627,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 90.00000,  27.00000, 152.00000, 141.00000,   0.86907,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 90.00000,  26.00000, 152.00000, 142.00000,   0.87143,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  26.00000, 153.00000, 142.00000,   0.88318,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 91.00000,  27.00000, 152.00000, 143.00000,   0.85822,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  27.00000, 153.00000, 143.00000,   0.79218,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 91.00000,  26.00000, 152.00000, 143.00000,   0.51641,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  27.00000, 152.00000, 138.00000,   0.50045,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  27.00000, 152.00000, 134.00000,   0.65001,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  27.00000, 151.00000, 141.00000,   0.77900,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  27.00000, 151.00000, 119.00000,   0.80640,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  26.00000, 152.00000, 138.00000,   0.64416,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  26.00000, 150.00000, 140.00000,   0.88478,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  25.00000, 153.00000, 123.00000,   0.78993,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  26.00000, 152.00000, 141.00000,   0.74977,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  26.00000, 152.00000, 140.00000,   0.88766,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  26.00000, 152.00000, 141.00000,   0.84595,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  27.00000, 152.00000, 140.00000,   0.85227,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  25.00000, 152.00000, 140.00000,   0.85829,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  25.00000, 151.00000, 140.00000,   0.79770,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  26.00000, 153.00000, 139.00000,   0.89699,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  26.00000, 151.00000, 138.00000,   0.90267,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  26.00000, 152.00000, 137.00000,   0.89247,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  27.00000, 152.00000, 134.00000,   0.88929,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  27.00000, 151.00000, 134.00000,   0.88685,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  26.00000, 152.00000, 126.00000,   0.82539,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  27.00000, 153.00000, 113.00000,   0.88197,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 91.00000,  27.00000, 153.00000, 102.00000,   0.86589,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 91.00000,  25.00000, 153.00000, 102.00000,   0.87217,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 91.00000,  25.00000, 153.00000,  99.00000,   0.83991,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([2, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  17.00000, 148.00000,  68.00000,   0.46858,   0.00000],\n","          [ 93.00000,  18.00000, 147.00000,  68.00000,   0.40807,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 95.00000,  16.00000, 144.00000,  83.00000,   0.62698,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 97.00000,  17.00000, 149.00000, 102.00000,   0.65446,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 98.00000,  18.00000, 151.00000, 112.00000,   0.85686,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 97.00000,  17.00000, 151.00000, 123.00000,   0.87634,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 96.00000,  16.00000, 147.00000, 127.00000,   0.88871,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 96.00000,  16.00000, 146.00000, 130.00000,   0.86175,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 96.00000,  17.00000, 142.00000, 128.00000,   0.87895,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 95.00000,  17.00000, 141.00000, 126.00000,   0.88812,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 95.00000,  17.00000, 141.00000, 125.00000,   0.87894,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 96.00000,  17.00000, 142.00000, 125.00000,   0.81442,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 95.00000,  17.00000, 142.00000, 125.00000,   0.84962,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 95.00000,  15.00000, 147.00000, 131.00000,   0.83067,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 96.00000,  14.00000, 147.00000, 130.00000,   0.85086,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 95.00000,  14.00000, 147.00000, 130.00000,   0.87560,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 97.00000,  16.00000, 146.00000, 132.00000,   0.83219,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 97.00000,  17.00000, 144.00000, 132.00000,   0.83372,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 96.00000,  18.00000, 144.00000, 130.00000,   0.82229,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 96.00000,  18.00000, 147.00000, 133.00000,   0.78810,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 97.00000,  20.00000, 148.00000, 135.00000,   0.82650,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 87.00000,  18.00000, 145.00000, 142.00000,   0.79962,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 95.00000,  20.00000, 144.00000, 132.00000,   0.85336,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 96.00000,  18.00000, 147.00000, 133.00000,   0.86499,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  20.00000, 144.00000, 134.00000,   0.87643,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 95.00000,  20.00000, 146.00000, 136.00000,   0.87277,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  19.00000, 144.00000, 134.00000,   0.86336,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  20.00000, 145.00000, 137.00000,   0.88500,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 90.00000,  19.00000, 141.00000, 133.00000,   0.86641,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 93.00000,  19.00000, 151.00000, 156.00000,   0.74776,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 91.00000,  21.00000, 142.00000, 138.00000,   0.86961,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  20.00000, 144.00000, 139.00000,   0.87860,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 91.00000,  18.00000, 151.00000, 149.00000,   0.86681,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  20.00000, 144.00000, 138.00000,   0.85741,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  20.00000, 146.00000, 141.00000,   0.82716,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  21.00000, 144.00000, 139.00000,   0.86212,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 90.00000,  21.00000, 142.00000, 140.00000,   0.87963,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 86.00000,  21.00000, 141.00000, 139.00000,   0.87217,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 89.00000,  21.00000, 141.00000, 138.00000,   0.87072,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 85.00000,  21.00000, 140.00000, 140.00000,   0.36260,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 88.00000,  21.00000, 140.00000, 134.00000,   0.69718,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 88.00000,  21.00000, 140.00000, 133.00000,   0.81522,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 87.00000,  21.00000, 137.00000, 133.00000,   0.68904,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 88.00000,  22.00000, 139.00000, 134.00000,   0.45328,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 88.00000,  21.00000, 136.00000, 130.00000,   0.86933,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 87.00000,  22.00000, 135.00000, 131.00000,   0.86589,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 88.00000,  22.00000, 139.00000, 137.00000,   0.81110,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 84.00000,  22.00000, 135.00000, 135.00000,   0.75258,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 85.00000,  22.00000, 138.00000, 133.00000,   0.35994,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 88.00000,  21.00000, 136.00000, 117.00000,   0.61001,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 86.00000,  22.00000, 135.00000, 115.00000,   0.67941,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 87.00000,  22.00000, 136.00000, 117.00000,   0.75964,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 86.00000,  21.00000, 135.00000, 116.00000,   0.74453,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 86.00000,  21.00000, 135.00000, 117.00000,   0.60918,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 86.00000,  22.00000, 137.00000, 137.00000,   0.27972,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 85.00000,  21.00000, 135.00000, 131.00000,   0.77612,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 87.00000,  22.00000, 136.00000, 138.00000,   0.80246,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 83.00000,  21.00000, 136.00000, 139.00000,   0.39333,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 85.00000,  19.00000, 136.00000, 134.00000,   0.80253,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 84.00000,  19.00000, 135.00000, 133.00000,   0.84000,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 86.00000,  19.00000, 137.00000, 133.00000,   0.64727,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 83.00000,  18.00000, 133.00000, 127.00000,   0.42600,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 86.00000,  17.00000, 135.00000, 127.00000,   0.59289,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 87.00000,  16.00000, 141.00000, 129.00000,   0.82742,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 94.00000,  15.00000, 144.00000, 129.00000,   0.86829,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 96.00000,  15.00000, 145.00000, 128.00000,   0.89084,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 96.00000,  14.00000, 144.00000, 127.00000,   0.87558,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 92.00000,  17.00000, 143.00000, 125.00000,   0.87882,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 51.00000,  22.00000, 121.00000, 195.00000,   0.37825,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 52.00000,  22.00000, 116.00000, 192.00000,   0.66473,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 51.00000,  20.00000, 108.00000, 184.00000,   0.33651,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 49.00000,  20.00000, 109.00000, 185.00000,   0.48251,   0.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 76.00000,  16.00000, 100.00000, 174.00000,   0.50793,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 77.00000,  17.00000, 102.00000, 177.00000,   0.60351,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 74.00000,  18.00000, 101.00000, 160.00000,   0.54350,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 76.00000,  17.00000, 101.00000, 121.00000,   0.69706,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([1, 6])\n","  dtype: torch.float32\n","   + tensor([[ 80.00000,  13.00000, 130.00000, 166.00000,   0.45466,   1.00000]], device='cuda:0')],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))],\n"," [Ultralytics YOLO <class 'ultralytics.yolo.engine.results.Boxes'> masks\n","  type: <class 'torch.Tensor'>\n","  shape: torch.Size([0, 6])\n","  dtype: torch.float32\n","   + tensor([], device='cuda:0', size=(0, 6))]]"]},"metadata":{},"execution_count":30}],"source":["results"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"37kcoMmzLp3m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699514354118,"user_tz":-330,"elapsed":75,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}},"outputId":"98217034-60b6-4c28-9093-bec61a9a750b"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 319/319 [00:00<00:00, 11912.67it/s]"]},{"output_type":"stream","name":"stdout","text":["95 189\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["fps = 2\n","limit = fps * 3\n","count = 0\n","phase4_count = phase5_count = phase4_idx = phase5_idx = phase6_idx = phase6_count = 0\n","flag4 = flag5 = flag6 = False\n","\n","for i in tqdm(range(len(results))):\n","  if i <= phase3_idx:\n","    count+=1\n","    continue\n","  if flag4 == True and flag5 == False and 0.0 in results[i][0].boxes.cls and (results[i][0].boxes.conf[0] > 0.5 or (len(results[i][0].boxes.conf)>1 and results[i][0].boxes.conf[1] > 0.5)):\n","    phase5_count = phase5_count + 1\n","    if phase5_count>=limit:\n","      flag5 = True\n","      phase5_idx = count\n","  elif flag4 == True and flag5 == False and 0.0 not in results[i][0].boxes.cls:\n","    phase5_count = 0\n","\n","  if flag4 == False and flag5 == False and 1.0 in results[i][0].boxes.cls and (results[i][0].boxes.conf[0] > 0.5 or (len(results[i][0].boxes.conf)>1 and results[i][0].boxes.conf[1] > 0.5)):\n","    phase4_count = phase4_count + 1\n","    if phase4_count>=limit:\n","      flag4 = True\n","      phase4_idx = count\n","\n","  elif flag4 == False and flag5 == False and 1.0 not in results[i][0].boxes.cls:\n","    phase4_count = 0\n","\n","  if flag4 == True and flag5 == True and flag6 == False and 0.0 not in results[i][0].boxes.cls:\n","    phase6_count +=1\n","    if phase6_count>=limit:\n","      flag6 = True\n","      phase6_idx = count\n","  elif flag4 == True and flag5 == True and flag6 == False and 0.0 in results[i][0].boxes.cls:\n","    phase6_count = 0\n","  count+=1\n","\n","\n","print(phase4_idx, phase5_idx)\n","\n"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"ZZoZ0fEEYLGI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699514354118,"user_tz":-330,"elapsed":18,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}},"outputId":"fae9538c-e458-4abe-ab8e-017a95c3f573"},"outputs":[{"output_type":"stream","name":"stdout","text":["1 60 63 95 189 263\n"]}],"source":["print(phase1_idx, phase2_idx, phase3_idx, phase4_idx, phase5_idx, phase6_idx)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"1UiuL-hWKYv8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699514375548,"user_tz":-330,"elapsed":21447,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}},"outputId":"2fff451f-3d06-48a0-de59-0902a8ae3363"},"outputs":[{"output_type":"stream","name":"stdout","text":["2023-11-09 07:19:21.381775: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-09 07:19:21.381839: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-09 07:19:21.381887: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-09 07:19:23.190895: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Ultralytics YOLOv8.0.20 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","Model summary (fused): 168 layers, 11126358 parameters, 0 gradients, 28.4 GFLOPs\n","image 1/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/100_masked_frame.png: 640x640 1 P, 6.6ms\n","image 2/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/101_masked_frame.png: 640x640 1 P, 7.4ms\n","image 3/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/102_masked_frame.png: 640x640 1 P, 6.9ms\n","image 4/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/103_masked_frame.png: 640x640 1 P, 7.9ms\n","image 5/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/104_masked_frame.png: 640x640 1 P, 7.5ms\n","image 6/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/105_masked_frame.png: 640x640 1 P, 6.9ms\n","image 7/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/106_masked_frame.png: 640x640 1 P, 9.2ms\n","image 8/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/107_masked_frame.png: 640x640 1 P, 7.6ms\n","image 9/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/108_masked_frame.png: 640x640 1 P, 6.9ms\n","image 10/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/109_masked_frame.png: 640x640 1 P, 7.2ms\n","image 11/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/10_masked_frame.png: 640x640 7.2ms\n","image 12/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/110_masked_frame.png: 640x640 1 P, 7.0ms\n","image 13/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/111_masked_frame.png: 640x640 1 P, 7.6ms\n","image 14/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/112_masked_frame.png: 640x640 1 P, 6.9ms\n","image 15/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/113_masked_frame.png: 640x640 1 P, 7.1ms\n","image 16/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/114_masked_frame.png: 640x640 1 P, 7.1ms\n","image 17/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/115_masked_frame.png: 640x640 1 P, 7.5ms\n","image 18/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/116_masked_frame.png: 640x640 1 P, 6.9ms\n","image 19/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/117_masked_frame.png: 640x640 1 P, 7.2ms\n","image 20/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/118_masked_frame.png: 640x640 1 P, 7.0ms\n","image 21/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/119_masked_frame.png: 640x640 1 P, 9.2ms\n","image 22/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/11_masked_frame.png: 640x640 14.5ms\n","image 23/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/120_masked_frame.png: 640x640 1 P, 7.0ms\n","image 24/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/121_masked_frame.png: 640x640 1 P, 7.0ms\n","image 25/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/122_masked_frame.png: 640x640 1 P, 7.4ms\n","image 26/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/123_masked_frame.png: 640x640 1 P, 7.5ms\n","image 27/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/124_masked_frame.png: 640x640 1 P, 7.3ms\n","image 28/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/125_masked_frame.png: 640x640 1 P, 7.2ms\n","image 29/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/126_masked_frame.png: 640x640 1 P, 7.3ms\n","image 30/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/127_masked_frame.png: 640x640 1 P, 7.1ms\n","image 31/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/128_masked_frame.png: 640x640 1 P, 7.8ms\n","image 32/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/129_masked_frame.png: 640x640 1 P, 7.2ms\n","image 33/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/12_masked_frame.png: 640x640 8.9ms\n","image 34/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/130_masked_frame.png: 640x640 1 P, 6.7ms\n","image 35/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/131_masked_frame.png: 640x640 1 P, 6.9ms\n","image 36/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/132_masked_frame.png: 640x640 1 P, 8.1ms\n","image 37/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/133_masked_frame.png: 640x640 1 P, 7.1ms\n","image 38/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/134_masked_frame.png: 640x640 1 P, 6.8ms\n","image 39/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/135_masked_frame.png: 640x640 1 P, 6.6ms\n","image 40/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/136_masked_frame.png: 640x640 1 P, 7.4ms\n","image 41/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/137_masked_frame.png: 640x640 1 P, 8.3ms\n","image 42/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/138_masked_frame.png: 640x640 1 P, 11.7ms\n","image 43/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/139_masked_frame.png: 640x640 1 P, 7.5ms\n","image 44/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/13_masked_frame.png: 640x640 7.6ms\n","image 45/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/140_masked_frame.png: 640x640 1 P, 7.0ms\n","image 46/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/141_masked_frame.png: 640x640 1 P, 7.1ms\n","image 47/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/142_masked_frame.png: 640x640 1 P, 7.9ms\n","image 48/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/143_masked_frame.png: 640x640 1 P, 7.7ms\n","image 49/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/144_masked_frame.png: 640x640 1 P, 7.4ms\n","image 50/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/145_masked_frame.png: 640x640 1 P, 7.1ms\n","image 51/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/146_masked_frame.png: 640x640 1 P, 8.2ms\n","image 52/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/147_masked_frame.png: 640x640 1 P, 8.0ms\n","image 53/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/148_masked_frame.png: 640x640 1 P, 8.5ms\n","image 54/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/149_masked_frame.png: 640x640 1 P, 7.2ms\n","image 55/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/14_masked_frame.png: 640x640 7.1ms\n","image 56/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/150_masked_frame.png: 640x640 1 P, 10.1ms\n","image 57/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/151_masked_frame.png: 640x640 1 P, 7.2ms\n","image 58/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/152_masked_frame.png: 640x640 1 P, 7.2ms\n","image 59/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/153_masked_frame.png: 640x640 1 P, 7.1ms\n","image 60/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/154_masked_frame.png: 640x640 1 P, 6.9ms\n","image 61/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/155_masked_frame.png: 640x640 1 P, 7.4ms\n","image 62/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/156_masked_frame.png: 640x640 1 P, 7.4ms\n","image 63/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/157_masked_frame.png: 640x640 1 P, 7.5ms\n","image 64/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/158_masked_frame.png: 640x640 1 P, 7.3ms\n","image 65/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/159_masked_frame.png: 640x640 1 P, 7.2ms\n","image 66/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/15_masked_frame.png: 640x640 7.1ms\n","image 67/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/160_masked_frame.png: 640x640 1 P, 7.2ms\n","image 68/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/161_masked_frame.png: 640x640 1 P, 7.2ms\n","image 69/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/162_masked_frame.png: 640x640 1 P, 10.8ms\n","image 70/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/163_masked_frame.png: 640x640 1 P, 7.3ms\n","image 71/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/164_masked_frame.png: 640x640 1 P, 7.0ms\n","image 72/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/165_masked_frame.png: 640x640 1 P, 8.6ms\n","image 73/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/166_masked_frame.png: 640x640 1 P, 12.2ms\n","image 74/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/167_masked_frame.png: 640x640 1 P, 13.0ms\n","image 75/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/168_masked_frame.png: 640x640 1 P, 7.0ms\n","image 76/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/169_masked_frame.png: 640x640 1 P, 7.4ms\n","image 77/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/16_masked_frame.png: 640x640 7.1ms\n","image 78/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/170_masked_frame.png: 640x640 1 P, 7.9ms\n","image 79/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/171_masked_frame.png: 640x640 1 P, 7.1ms\n","image 80/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/172_masked_frame.png: 640x640 1 P, 7.2ms\n","image 81/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/173_masked_frame.png: 640x640 1 P, 7.0ms\n","image 82/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/174_masked_frame.png: 640x640 1 P, 9.3ms\n","image 83/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/175_masked_frame.png: 640x640 1 P, 7.1ms\n","image 84/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/176_masked_frame.png: 640x640 1 P, 7.1ms\n","image 85/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/177_masked_frame.png: 640x640 7.1ms\n","image 86/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/178_masked_frame.png: 640x640 6.9ms\n","image 87/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/179_masked_frame.png: 640x640 7.0ms\n","image 88/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/17_masked_frame.png: 640x640 7.0ms\n","image 89/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/180_masked_frame.png: 640x640 7.8ms\n","image 90/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/181_masked_frame.png: 640x640 7.4ms\n","image 91/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/182_masked_frame.png: 640x640 7.1ms\n","image 92/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/183_masked_frame.png: 640x640 6.9ms\n","image 93/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/184_masked_frame.png: 640x640 7.1ms\n","image 94/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/185_masked_frame.png: 640x640 1 B, 7.2ms\n","image 95/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/186_masked_frame.png: 640x640 1 B, 7.3ms\n","image 96/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/187_masked_frame.png: 640x640 1 B, 7.2ms\n","image 97/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/188_masked_frame.png: 640x640 1 B, 7.0ms\n","image 98/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/189_masked_frame.png: 640x640 1 B, 10.5ms\n","image 99/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/18_masked_frame.png: 640x640 7.3ms\n","image 100/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/190_masked_frame.png: 640x640 1 B, 7.3ms\n","image 101/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/191_masked_frame.png: 640x640 1 B, 7.3ms\n","image 102/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/192_masked_frame.png: 640x640 1 B, 7.0ms\n","image 103/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/193_masked_frame.png: 640x640 1 B, 7.3ms\n","image 104/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/194_masked_frame.png: 640x640 1 B, 7.1ms\n","image 105/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/195_masked_frame.png: 640x640 1 B, 7.3ms\n","image 106/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/196_masked_frame.png: 640x640 7.1ms\n","image 107/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/197_masked_frame.png: 640x640 7.1ms\n","image 108/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/198_masked_frame.png: 640x640 1 B, 7.1ms\n","image 109/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/199_masked_frame.png: 640x640 1 B, 7.5ms\n","image 110/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/19_masked_frame.png: 640x640 7.4ms\n","image 111/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/1_masked_frame.png: 640x640 7.0ms\n","image 112/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/200_masked_frame.png: 640x640 1 B, 7.1ms\n","image 113/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/201_masked_frame.png: 640x640 1 B, 6.8ms\n","image 114/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/202_masked_frame.png: 640x640 1 B, 8.1ms\n","image 115/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/203_masked_frame.png: 640x640 6.8ms\n","image 116/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/204_masked_frame.png: 640x640 1 B, 7.6ms\n","image 117/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/205_masked_frame.png: 640x640 7.3ms\n","image 118/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/206_masked_frame.png: 640x640 1 B, 7.3ms\n","image 119/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/207_masked_frame.png: 640x640 1 B, 6.9ms\n","image 120/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/208_masked_frame.png: 640x640 1 B, 7.0ms\n","image 121/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/209_masked_frame.png: 640x640 1 B, 7.2ms\n","image 122/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/20_masked_frame.png: 640x640 7.3ms\n","image 123/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/210_masked_frame.png: 640x640 1 B, 7.2ms\n","image 124/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/211_masked_frame.png: 640x640 1 B, 6.9ms\n","image 125/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/212_masked_frame.png: 640x640 1 B, 9.0ms\n","image 126/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/213_masked_frame.png: 640x640 1 B, 8.1ms\n","image 127/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/214_masked_frame.png: 640x640 8.2ms\n","image 128/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/215_masked_frame.png: 640x640 1 B, 10.3ms\n","image 129/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/216_masked_frame.png: 640x640 1 B, 11.3ms\n","image 130/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/217_masked_frame.png: 640x640 1 B, 7.2ms\n","image 131/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/218_masked_frame.png: 640x640 1 B, 7.2ms\n","image 132/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/219_masked_frame.png: 640x640 1 B, 7.6ms\n","image 133/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/21_masked_frame.png: 640x640 7.4ms\n","image 134/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/220_masked_frame.png: 640x640 1 B, 7.0ms\n","image 135/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/221_masked_frame.png: 640x640 1 B, 7.2ms\n","image 136/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/222_masked_frame.png: 640x640 1 B, 7.8ms\n","image 137/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/223_masked_frame.png: 640x640 9.0ms\n","image 138/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/224_masked_frame.png: 640x640 7.1ms\n","image 139/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/225_masked_frame.png: 640x640 7.4ms\n","image 140/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/226_masked_frame.png: 640x640 1 B, 7.7ms\n","image 141/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/227_masked_frame.png: 640x640 1 B, 13.0ms\n","image 142/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/228_masked_frame.png: 640x640 1 B, 7.1ms\n","image 143/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/229_masked_frame.png: 640x640 1 B, 6.8ms\n","image 144/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/22_masked_frame.png: 640x640 7.2ms\n","image 145/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/230_masked_frame.png: 640x640 7.2ms\n","image 146/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/231_masked_frame.png: 640x640 1 B, 7.5ms\n","image 147/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/232_masked_frame.png: 640x640 1 B, 7.0ms\n","image 148/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/233_masked_frame.png: 640x640 1 B, 7.0ms\n","image 149/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/234_masked_frame.png: 640x640 7.0ms\n","image 150/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/235_masked_frame.png: 640x640 1 B, 6.9ms\n","image 151/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/236_masked_frame.png: 640x640 1 B, 8.5ms\n","image 152/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/237_masked_frame.png: 640x640 1 B, 8.2ms\n","image 153/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/238_masked_frame.png: 640x640 1 B, 7.1ms\n","image 154/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/239_masked_frame.png: 640x640 7.0ms\n","image 155/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/23_masked_frame.png: 640x640 7.4ms\n","image 156/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/240_masked_frame.png: 640x640 1 B, 8.2ms\n","image 157/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/241_masked_frame.png: 640x640 1 B, 11.9ms\n","image 158/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/242_masked_frame.png: 640x640 1 B, 7.0ms\n","image 159/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/243_masked_frame.png: 640x640 1 B, 6.7ms\n","image 160/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/244_masked_frame.png: 640x640 1 B, 6.9ms\n","image 161/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/245_masked_frame.png: 640x640 7.4ms\n","image 162/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/246_masked_frame.png: 640x640 1 B, 6.8ms\n","image 163/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/247_masked_frame.png: 640x640 1 B, 8.9ms\n","image 164/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/248_masked_frame.png: 640x640 11.6ms\n","image 165/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/249_masked_frame.png: 640x640 1 B, 6.9ms\n","image 166/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/24_masked_frame.png: 640x640 6.9ms\n","image 167/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/250_masked_frame.png: 640x640 1 B, 7.0ms\n","image 168/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/251_masked_frame.png: 640x640 1 B, 10.1ms\n","image 169/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/252_masked_frame.png: 640x640 6.8ms\n","image 170/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/253_masked_frame.png: 640x640 1 B, 7.0ms\n","image 171/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/254_masked_frame.png: 640x640 1 B, 7.0ms\n","image 172/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/255_masked_frame.png: 640x640 1 B, 7.3ms\n","image 173/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/256_masked_frame.png: 640x640 1 B, 10.6ms\n","image 174/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/257_masked_frame.png: 640x640 1 B, 6.9ms\n","image 175/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/258_masked_frame.png: 640x640 1 B, 7.3ms\n","image 176/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/259_masked_frame.png: 640x640 7.3ms\n","image 177/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/25_masked_frame.png: 640x640 7.4ms\n","image 178/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/260_masked_frame.png: 640x640 7.7ms\n","image 179/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/261_masked_frame.png: 640x640 7.0ms\n","image 180/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/262_masked_frame.png: 640x640 7.4ms\n","image 181/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/263_masked_frame.png: 640x640 7.1ms\n","image 182/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/264_masked_frame.png: 640x640 9.9ms\n","image 183/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/265_masked_frame.png: 640x640 8.3ms\n","image 184/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/266_masked_frame.png: 640x640 10.3ms\n","image 185/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/267_masked_frame.png: 640x640 7.0ms\n","image 186/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/268_masked_frame.png: 640x640 7.0ms\n","image 187/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/269_masked_frame.png: 640x640 7.2ms\n","image 188/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/26_masked_frame.png: 640x640 6.9ms\n","image 189/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/270_masked_frame.png: 640x640 7.8ms\n","image 190/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/271_masked_frame.png: 640x640 6.7ms\n","image 191/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/272_masked_frame.png: 640x640 8.2ms\n","image 192/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/273_masked_frame.png: 640x640 6.8ms\n","image 193/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/274_masked_frame.png: 640x640 6.7ms\n","image 194/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/275_masked_frame.png: 640x640 6.6ms\n","image 195/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/276_masked_frame.png: 640x640 6.7ms\n","image 196/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/277_masked_frame.png: 640x640 6.5ms\n","image 197/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/278_masked_frame.png: 640x640 6.9ms\n","image 198/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/279_masked_frame.png: 640x640 7.0ms\n","image 199/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/27_masked_frame.png: 640x640 7.0ms\n","image 200/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/280_masked_frame.png: 640x640 6.9ms\n","image 201/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/281_masked_frame.png: 640x640 7.0ms\n","image 202/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/282_masked_frame.png: 640x640 7.2ms\n","image 203/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/283_masked_frame.png: 640x640 7.2ms\n","image 204/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/284_masked_frame.png: 640x640 6.8ms\n","image 205/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/285_masked_frame.png: 640x640 6.9ms\n","image 206/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/286_masked_frame.png: 640x640 7.2ms\n","image 207/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/287_masked_frame.png: 640x640 7.9ms\n","image 208/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/288_masked_frame.png: 640x640 7.2ms\n","image 209/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/289_masked_frame.png: 640x640 6.8ms\n","image 210/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/28_masked_frame.png: 640x640 6.9ms\n","image 211/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/290_masked_frame.png: 640x640 7.4ms\n","image 212/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/291_masked_frame.png: 640x640 6.6ms\n","image 213/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/292_masked_frame.png: 640x640 7.0ms\n","image 214/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/293_masked_frame.png: 640x640 1 B, 6.9ms\n","image 215/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/294_masked_frame.png: 640x640 6.7ms\n","image 216/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/295_masked_frame.png: 640x640 6.7ms\n","image 217/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/296_masked_frame.png: 640x640 6.9ms\n","image 218/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/297_masked_frame.png: 640x640 7.5ms\n","image 219/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/298_masked_frame.png: 640x640 12.2ms\n","image 220/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/299_masked_frame.png: 640x640 7.1ms\n","image 221/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/29_masked_frame.png: 640x640 6.7ms\n","image 222/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/2_masked_frame.png: 640x640 6.9ms\n","image 223/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/300_masked_frame.png: 640x640 6.8ms\n","image 224/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/301_masked_frame.png: 640x640 6.7ms\n","image 225/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/302_masked_frame.png: 640x640 7.9ms\n","image 226/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/303_masked_frame.png: 640x640 6.8ms\n","image 227/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/304_masked_frame.png: 640x640 6.7ms\n","image 228/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/305_masked_frame.png: 640x640 6.8ms\n","image 229/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/306_masked_frame.png: 640x640 6.8ms\n","image 230/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/307_masked_frame.png: 640x640 6.7ms\n","image 231/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/308_masked_frame.png: 640x640 7.1ms\n","image 232/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/309_masked_frame.png: 640x640 6.7ms\n","image 233/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/30_masked_frame.png: 640x640 6.8ms\n","image 234/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/310_masked_frame.png: 640x640 6.8ms\n","image 235/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/311_masked_frame.png: 640x640 1 P, 7.5ms\n","image 236/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/312_masked_frame.png: 640x640 1 P, 7.6ms\n","image 237/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/313_masked_frame.png: 640x640 1 P, 10.6ms\n","image 238/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/314_masked_frame.png: 640x640 7.2ms\n","image 239/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/315_masked_frame.png: 640x640 7.2ms\n","image 240/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/316_masked_frame.png: 640x640 1 P, 6.9ms\n","image 241/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/317_masked_frame.png: 640x640 10.0ms\n","image 242/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/318_masked_frame.png: 640x640 9.6ms\n","image 243/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/319_masked_frame.png: 640x640 10.5ms\n","image 244/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/31_masked_frame.png: 640x640 7.1ms\n","image 245/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/32_masked_frame.png: 640x640 7.2ms\n","image 246/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/33_masked_frame.png: 640x640 6.7ms\n","image 247/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/34_masked_frame.png: 640x640 7.0ms\n","image 248/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/35_masked_frame.png: 640x640 11.3ms\n","image 249/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/36_masked_frame.png: 640x640 6.8ms\n","image 250/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/37_masked_frame.png: 640x640 6.9ms\n","image 251/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/38_masked_frame.png: 640x640 7.5ms\n","image 252/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/39_masked_frame.png: 640x640 7.0ms\n","image 253/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/3_masked_frame.png: 640x640 7.8ms\n","image 254/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/40_masked_frame.png: 640x640 7.1ms\n","image 255/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/41_masked_frame.png: 640x640 7.3ms\n","image 256/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/42_masked_frame.png: 640x640 7.0ms\n","image 257/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/43_masked_frame.png: 640x640 7.0ms\n","image 258/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/44_masked_frame.png: 640x640 10.0ms\n","image 259/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/45_masked_frame.png: 640x640 7.1ms\n","image 260/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/46_masked_frame.png: 640x640 7.3ms\n","image 261/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/47_masked_frame.png: 640x640 7.3ms\n","image 262/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/48_masked_frame.png: 640x640 7.2ms\n","image 263/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/49_masked_frame.png: 640x640 7.3ms\n","image 264/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/4_masked_frame.png: 640x640 7.6ms\n","image 265/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/50_masked_frame.png: 640x640 7.0ms\n","image 266/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/51_masked_frame.png: 640x640 7.3ms\n","image 267/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/52_masked_frame.png: 640x640 7.1ms\n","image 268/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/53_masked_frame.png: 640x640 6.6ms\n","image 269/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/54_masked_frame.png: 640x640 7.0ms\n","image 270/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/55_masked_frame.png: 640x640 7.5ms\n","image 271/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/56_masked_frame.png: 640x640 6.6ms\n","image 272/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/57_masked_frame.png: 640x640 7.2ms\n","image 273/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/58_masked_frame.png: 640x640 7.4ms\n","image 274/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/59_masked_frame.png: 640x640 8.8ms\n","image 275/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/5_masked_frame.png: 640x640 7.2ms\n","image 276/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/60_masked_frame.png: 640x640 8.8ms\n","image 277/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/61_masked_frame.png: 640x640 6.8ms\n","image 278/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/62_masked_frame.png: 640x640 7.2ms\n","image 279/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/63_masked_frame.png: 640x640 7.0ms\n","image 280/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/64_masked_frame.png: 640x640 7.5ms\n","image 281/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/65_masked_frame.png: 640x640 8.0ms\n","image 282/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/66_masked_frame.png: 640x640 8.0ms\n","image 283/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/67_masked_frame.png: 640x640 7.0ms\n","image 284/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/68_masked_frame.png: 640x640 6.9ms\n","image 285/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/69_masked_frame.png: 640x640 7.3ms\n","image 286/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/6_masked_frame.png: 640x640 7.6ms\n","image 287/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/70_masked_frame.png: 640x640 7.6ms\n","image 288/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/71_masked_frame.png: 640x640 8.7ms\n","image 289/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/72_masked_frame.png: 640x640 7.0ms\n","image 290/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/73_masked_frame.png: 640x640 7.2ms\n","image 291/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/74_masked_frame.png: 640x640 7.3ms\n","image 292/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/75_masked_frame.png: 640x640 7.6ms\n","image 293/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/76_masked_frame.png: 640x640 7.7ms\n","image 294/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/77_masked_frame.png: 640x640 10.1ms\n","image 295/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/78_masked_frame.png: 640x640 7.4ms\n","image 296/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/79_masked_frame.png: 640x640 7.3ms\n","image 297/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/7_masked_frame.png: 640x640 7.1ms\n","image 298/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/80_masked_frame.png: 640x640 11.2ms\n","image 299/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/81_masked_frame.png: 640x640 7.0ms\n","image 300/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/82_masked_frame.png: 640x640 7.1ms\n","image 301/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/83_masked_frame.png: 640x640 1 P, 6.9ms\n","image 302/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/84_masked_frame.png: 640x640 7.3ms\n","image 303/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/85_masked_frame.png: 640x640 1 P, 7.0ms\n","image 304/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/86_masked_frame.png: 640x640 1 P, 7.5ms\n","image 305/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/87_masked_frame.png: 640x640 1 P, 6.9ms\n","image 306/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/88_masked_frame.png: 640x640 1 P, 7.0ms\n","image 307/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/89_masked_frame.png: 640x640 7.0ms\n","image 308/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/8_masked_frame.png: 640x640 7.1ms\n","image 309/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/90_masked_frame.png: 640x640 7.0ms\n","image 310/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/91_masked_frame.png: 640x640 1 P, 7.0ms\n","image 311/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/92_masked_frame.png: 640x640 1 P, 7.7ms\n","image 312/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/93_masked_frame.png: 640x640 1 P, 7.4ms\n","image 313/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/94_masked_frame.png: 640x640 1 P, 7.1ms\n","image 314/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/95_masked_frame.png: 640x640 1 P, 7.4ms\n","image 315/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/96_masked_frame.png: 640x640 1 P, 7.6ms\n","image 316/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/97_masked_frame.png: 640x640 1 P, 7.0ms\n","image 317/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/98_masked_frame.png: 640x640 1 P, 7.3ms\n","image 318/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/99_masked_frame.png: 640x640 1 P, 9.3ms\n","image 319/319 /content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3/9_masked_frame.png: 640x640 7.6ms\n","Speed: 0.6ms pre-process, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"]}],"source":["!yolo task=detect mode=predict model='/content/drive/MyDrive/ETVProject/ETV_Project/detect/train/weights/best.pt' conf=0.5 source='/content/drive/MyDrive/ETVProject/ETV_Project/chiari_predictions3' save=True"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"9VuzlmvR4VdO","executionInfo":{"status":"ok","timestamp":1699514375548,"user_tz":-330,"elapsed":41,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["imlist = natsorted(os.listdir(\"/content/runs/detect/predict/\"))"]},{"cell_type":"code","execution_count":35,"metadata":{"id":"I_3bka2U4CNB","executionInfo":{"status":"ok","timestamp":1699514375548,"user_tz":-330,"elapsed":40,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["from PIL import Image\n","from PIL import ImageDraw\n","from PIL import ImageFont\n"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"4GFH3PtNJuLJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699514379807,"user_tz":-330,"elapsed":4298,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}},"outputId":"2ac7693a-f72b-40fc-9a8a-0bd3f7b730ae"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 319/319 [00:04<00:00, 71.49it/s]\n"]}],"source":["count = 0\n","for f in tqdm(imlist):\n","  if '.png' in f:\n","    filename = \"/content/runs/detect/predict/\"+f\n","    img = Image.open(filename)\n","    I1 = ImageDraw.Draw(img)\n","\n","    if count >=phase6_idx:\n","      I1.text((10, 10), \"5 Phases Complete\", fill =(255, 0, 0))\n","    elif count >= phase5_idx:\n","      I1.text((10, 10), \"Dilation\", fill =(255, 0, 0))\n","    elif count >= phase4_idx:\n","      I1.text((10, 10), \"Puncturing\", fill =(255, 0, 0))\n","    elif count >= phase3_idx:\n","      I1.text((10, 10), \"Third Ventricle\", fill =(255, 0, 0))\n","    elif count >= phase2_idx:\n","      I1.text((10, 10), \"Entering Third Ventricle\", fill =(255, 0, 0))\n","    elif count >= phase1_idx:\n","      I1.text((10, 10), \"Lateral Ventricle\", fill =(255, 0, 0))\n","    #img.show()\n","    img=img.save(filename)\n","    count+=1"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"df1QYY8FXDYv","executionInfo":{"status":"ok","timestamp":1699514379808,"user_tz":-330,"elapsed":42,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["import cv2\n","import glob"]},{"cell_type":"code","execution_count":38,"metadata":{"id":"ZEANWhukYL1c","executionInfo":{"status":"ok","timestamp":1699514379808,"user_tz":-330,"elapsed":41,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["frameSize = (224, 224)\n","out = cv2.VideoWriter('/content/drive/MyDrive/ETVProject/ETV_Project/chiari_opt.avi',cv2.VideoWriter_fourcc(*'DIVX'), 2, frameSize)"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"5u_zUusVYQEX","executionInfo":{"status":"ok","timestamp":1699514379809,"user_tz":-330,"elapsed":41,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["test_images = natsorted(glob.glob(\"/content/runs/detect/predict/*.png\"))"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"eh9_-zHCYgcj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1699514380440,"user_tz":-330,"elapsed":672,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}},"outputId":"1a130099-b0a9-4006-9501-a04299257ce0"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 319/319 [00:00<00:00, 585.35it/s]\n"]}],"source":["for filename in tqdm(test_images):\n","    img = cv2.imread(filename)\n","    out.write(img)\n"]},{"cell_type":"code","execution_count":41,"metadata":{"id":"rF1viMrqYmRR","executionInfo":{"status":"ok","timestamp":1699514380441,"user_tz":-330,"elapsed":16,"user":{"displayName":"Agastya Thoppur","userId":"05186951899722200987"}}},"outputs":[],"source":["\n","out.release()"]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyPVutTZpCWWZgqg0pO4WjT3"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}